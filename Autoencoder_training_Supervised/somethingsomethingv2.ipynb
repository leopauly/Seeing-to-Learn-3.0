{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the 20BN-something-something Dataset V2\n",
    "==================================================\n",
    "\n",
    "`Something-something-v2 <https://20bn.com/datasets/something-something>`_  is an action recognition dataset\n",
    "of realistic action videos, collected from YouTube. With 220,847 short trimmed videos\n",
    "from 174 action categories, it is one of the largest and most widely used dataset in the research\n",
    "community for benchmarking state-of-the-art video action recognition models. This tutorial\n",
    "will go through the steps of preparing this dataset for GluonCV.\n",
    "\n",
    "\n",
    "Download\n",
    "--------\n",
    "\n",
    "Please refer to the `official website <https://20bn.com/datasets/something-something>`_ to download the videos.\n",
    "The video data is provided as one large TGZ archive, split into parts of 1 GB max (there are 20 parts). The total download size is 19.4 GB.\n",
    "The archive contains webm-files using the VP9 codec. Files are numbered from 1 to 220847.\n",
    "Please use the provided md5sum to check if your downloaded parts are complete.\n",
    "\n",
    "============================================== ======\n",
    "Filename                                        Size\n",
    "============================================== ======\n",
    "20bn-something-something-v2-00                  1 GB\n",
    "20bn-something-something-v2-01                  1 GB\n",
    "20bn-something-something-v2-02                  1 GB\n",
    "20bn-something-something-v2-03                  1 GB\n",
    "20bn-something-something-v2-04                  1 GB\n",
    "20bn-something-something-v2-05                  1 GB\n",
    "20bn-something-something-v2-06                  1 GB\n",
    "20bn-something-something-v2-07                  1 GB\n",
    "20bn-something-something-v2-08                  1 GB\n",
    "20bn-something-something-v2-09                  1 GB\n",
    "20bn-something-something-v2-10                  1 GB\n",
    "20bn-something-something-v2-11                  1 GB\n",
    "20bn-something-something-v2-12                  1 GB\n",
    "20bn-something-something-v2-13                  1 GB\n",
    "20bn-something-something-v2-14                  1 GB\n",
    "20bn-something-something-v2-15                  1 GB\n",
    "20bn-something-something-v2-16                  1 GB\n",
    "20bn-something-something-v2-17                  1 GB\n",
    "20bn-something-something-v2-18                  1 GB\n",
    "20bn-something-something-v2-19                 445 MB\n",
    "============================================== ======\n",
    "\n",
    "Once confirmed, you can use the following command to unzip the videos.\n",
    "\n",
    ".. code-block:: bash\n",
    "\n",
    "   cat 20bn-something-something-v2-?? | tar zx\n",
    "\n",
    "Suppose by default the root directory for your data is ``ROOT=~/.mxnet/datasets/somethingsomethingv2``,\n",
    "all the videos will be stored at ``ROOT/20bn-something-something-v2`` now.\n",
    "Then, download the annotations and put them into folder ``ROOT/annotations``.\n",
    "\n",
    "============================================== ======\n",
    "Filename                                        Size\n",
    "============================================== ======\n",
    "something-something-v2-labels.json               9 KB\n",
    "something-something-v2-train.json               26 MB\n",
    "something-something-v2-validation.json         3.7 MB\n",
    "something-something-v2-test.json               448 KB\n",
    "============================================== ======\n",
    "\n",
    "\n",
    "Preprocess\n",
    "----------\n",
    "\n",
    "The easiest way to prepare the dataset is to download helper script\n",
    ":download:`somethingsomethingv2.py<../../../scripts/datasets/somethingsomethingv2.py>` and run the following command:\n",
    "\n",
    ".. code-block:: bash\n",
    "\n",
    "   python somethingsomethingv2.py\n",
    "\n",
    "This script will help you decode the videos to raw frames and generate training files for standard data loading.\n",
    "The video frames will be saved at ``ROOT/20bn-something-something-v2-frames``. The training files will be\n",
    "saved at ``ROOT/annotations``. The data preparation process may take a while. The total time to prepare\n",
    "the dataset depends on your machine. For example, it takes about 6 hours on an AWS EC2 instance with EBS.\n",
    "\n",
    "Once the script is done, you can start training your action recognition models on something-something-v2 dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
