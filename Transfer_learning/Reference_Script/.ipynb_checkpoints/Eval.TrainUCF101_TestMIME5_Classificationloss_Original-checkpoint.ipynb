{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author : @leopauly\n",
      "Program: Testing pre-trined feature extractors on manipulation dataset\n"
     ]
    }
   ],
   "source": [
    "print('Author : @leopauly')\n",
    "print('Program: Testing pre-trined feature extractors on manipulation dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from six.moves import xrange \n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage import io\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Custom scripts\n",
    "import lscript as lsp\n",
    "import modelling as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height=112 \n",
    "width=112 \n",
    "channel=3\n",
    "crop_size=112\n",
    "cluster_length=16\n",
    "feature_size=8192\n",
    "num_videos_per_class_test=5\n",
    "num_class_test=5\n",
    "load_saved_weights=True\n",
    "saved_path='/nobackup/leopauly/S2l/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:392: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", name=\"conv1\", input_shape=(16, 112, ..., padding=\"same\")`\n",
      "  input_shape=input_shape))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:394: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool1'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:397: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", name=\"conv2\", padding=\"same\")`\n",
      "  border_mode='same', name='conv2'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:399: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool2'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:402: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv3a'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:404: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv3b'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:406: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool3'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:409: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv4a'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:411: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv4b'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:413: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool4'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:416: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv5a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv5a'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:418: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv5b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv5b'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Seeing-to-Learn-3.0/Transfer_learning/modelling.py:421: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool5\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool5'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "zeropad5 (ZeroPadding3D)     (None, 2, 8, 8, 512)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 101)               413797    \n",
      "=================================================================\n",
      "Total params: 78,409,573\n",
      "Trainable params: 78,409,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Miscellenious items finished..!!\n"
     ]
    }
   ],
   "source": [
    "## Defining placeholders in tf for images and targets\n",
    "x_image = tf.placeholder(tf.float32, [None, cluster_length,height,width,channel],name='x') \n",
    "\n",
    "model_keras = md.C3D_ucf101_training_model_tf(summary=True)\n",
    "out=model_keras(x_image)\n",
    "\n",
    "print('Miscellenious items finished..!!',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /nobackup/leopauly/S2l/activity_model.ckpt-67\n",
      "Model restored from file: /nobackup/leopauly/S2l/\n"
     ]
    }
   ],
   "source": [
    "## Start the session with logging placement.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "sess.run(init_op)\n",
    "\n",
    "## Restore model weights from previously saved model\n",
    "saver = tf.train.Saver()\n",
    "if(load_saved_weights):\n",
    "    saver.restore(sess, os.path.join(saved_path,'activity_model.ckpt-67'))\n",
    "    print(\"Model restored from file: %s\" % saved_path,flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature extraction from testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extraction of features \n",
    "def extract_video_features(vid):\n",
    "    vid_=vid.reshape(-1,cluster_length,height,width,channel)\n",
    "    f_v = sess.graph.get_tensor_by_name('flatten_1/Reshape:0') #('flatten_1/Reshape:0') #('pool4/MaxPool3D:0') #('dropout_2/cond/Merge:0') #('fc8/BiasAdd:0') \n",
    "    f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 })#f_v_val=sess.run([y_pred], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 })\n",
    "    features=np.reshape(f_v_val,(-1))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Uniform smapling of frames from the entire video\n",
    "def get_compress_frames_data(video_filepath, num_frames_per_clip=16):\n",
    "  ret_arr = []\n",
    "  for _, _, filenames in os.walk(video_filepath):\n",
    "    filenames = sorted(filenames)\n",
    "    jump=math.floor((len(filenames)/num_frames_per_clip))\n",
    "    loop=0\n",
    "    for i in range(0,len(filenames),jump):\n",
    "      if (loop>15): break\n",
    "      if (filenames[i].endswith('.png')):\n",
    "        image_name = str(video_filepath) + '/' + str(filenames[i])\n",
    "        img = Image.open(image_name)\n",
    "        img_data = np.array(img)\n",
    "        img_data = cv2.resize(img_data,(crop_size,crop_size))\n",
    "        ret_arr.append(img_data)\n",
    "        loop=loop+1\n",
    "  ret_arr=np.array(ret_arr) #ret_arr=ret_arr/255\n",
    "  return ret_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feature extraction\n",
    "def get_features_from_class(class_folder):\n",
    "    feature_set_a=[]\n",
    "    base_dir_a=class_folder\n",
    "    sub_dir_a=os.listdir(base_dir_a)\n",
    "    sub_dir_a=sorted(sub_dir_a)\n",
    "    if '.DS_Store' in sub_dir_a:\n",
    "        sub_dir_a.remove('.DS_Store')\n",
    "    num_videos_per_class_test_loop=0\n",
    "    for sub_dir_a_ in sub_dir_a:\n",
    "        sub_sub_dir_a=os.listdir(base_dir_a+sub_dir_a_+'/')\n",
    "        for sub_sub_dir_a_ in sub_sub_dir_a:\n",
    "            if(num_videos_per_class_test_loop>=num_videos_per_class_test): break\n",
    "            video_filepath=base_dir_a+sub_dir_a_+'/'+sub_sub_dir_a_\n",
    "            print('Extracting feature from:',video_filepath)\n",
    "            vid_a=get_compress_frames_data(video_filepath)\n",
    "            feature_set_a.append(extract_video_features(vid_a))\n",
    "            num_videos_per_class_test_loop+=1\n",
    "    return np.array(feature_set_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/1/11709Oct31/hd_kinect_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/1/11709Oct31/rd_kinect_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/1/11709Oct31/RD_sk_right_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/1/11709Oct31/RD_sk_left_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/1/11710Oct31/hd_kinect_rgb\n"
     ]
    }
   ],
   "source": [
    "feature_set_a=get_features_from_class('/nobackup/leopauly/MIME/MIME_videos_frames/1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/2/11044Oct26/hd_kinect_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/2/11044Oct26/rd_kinect_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/2/11044Oct26/RD_sk_right_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/2/11044Oct26/RD_sk_left_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/2/11045Oct26/hd_kinect_rgb\n"
     ]
    }
   ],
   "source": [
    "feature_set_b=get_features_from_class('/nobackup/leopauly/MIME/MIME_videos_frames/2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/3/11286Oct30/hd_kinect_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/3/11286Oct30/rd_kinect_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/3/11286Oct30/RD_sk_right_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/3/11286Oct30/RD_sk_left_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/3/11287Oct30/hd_kinect_rgb\n"
     ]
    }
   ],
   "source": [
    "feature_set_c=get_features_from_class('/nobackup/leopauly/MIME/MIME_videos_frames/3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/4/10000Oct16/hd_kinect_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/4/10000Oct16/rd_kinect_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/4/10000Oct16/RD_sk_right_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/4/10000Oct16/RD_sk_left_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/4/10001Oct16/hd_kinect_rgb\n"
     ]
    }
   ],
   "source": [
    "feature_set_d=get_features_from_class('/nobackup/leopauly/MIME/MIME_videos_frames/4/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/5/10070Oct16/hd_kinect_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/5/10070Oct16/rd_kinect_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/5/10070Oct16/RD_sk_right_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/5/10070Oct16/RD_sk_left_rgb\n",
      "Extracting feature from: /nobackup/leopauly/MIME/MIME_videos_frames/5/10071Oct16/hd_kinect_rgb\n"
     ]
    }
   ],
   "source": [
    "feature_set_e=get_features_from_class('/nobackup/leopauly/MIME/MIME_videos_frames/5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing test data: Features\n",
    "hf = h5py.File('/nobackup/leopauly/S2l3.0/Features_Storage/feature_trainUCF101_testmime5_conv5.h5', 'w')\n",
    "hf.create_dataset('feature_set_a', data=feature_set_a)\n",
    "hf.create_dataset('feature_set_b', data=feature_set_b)\n",
    "hf.create_dataset('feature_set_c', data=feature_set_c)\n",
    "hf.create_dataset('feature_set_d', data=feature_set_d)\n",
    "hf.create_dataset('feature_set_e', data=feature_set_e)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Reading test data: Features\n",
    "\n",
    "hf = h5py.File('/nobackup/leopauly/S2l3.0/Features_Storage/feature_trainUCF101_testmime5_conv5.h5', 'r')\n",
    "feature_set_a=np.array(hf.get('feature_set_a'))\n",
    "feature_set_b=np.array(hf.get('feature_set_b'))\n",
    "feature_set_c=np.array(hf.get('feature_set_c'))\n",
    "feature_set_d=np.array(hf.get('feature_set_d'))\n",
    "feature_set_e=np.array(hf.get('feature_set_e'))\n",
    "hf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 30})\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "\n",
    "## TSNE compression\n",
    "tsne_obj = PCA(n_components=2)\n",
    "points=np.concatenate((feature_set_a,feature_set_b,feature_set_c,feature_set_d,feature_set_e),axis=0)\n",
    "tsne_obj.fit(points) \n",
    "\n",
    "vis_tsne_a=tsne_obj.transform(feature_set_a) \n",
    "vis_tsne_a=np.array(vis_tsne_a)\n",
    "\n",
    "vis_tsne_b=tsne_obj.transform(feature_set_b) \n",
    "vis_tsne_b=np.array(vis_tsne_b)\n",
    "\n",
    "vis_tsne_c=tsne_obj.transform(feature_set_c) \n",
    "vis_tsne_c=np.array(vis_tsne_c)\n",
    "\n",
    "vis_tsne_d=tsne_obj.fit_transform(feature_set_d) \n",
    "vis_tsne_d=np.array(vis_tsne_d)\n",
    "\n",
    "vis_tsne_e=tsne_obj.fit_transform(feature_set_e) \n",
    "vis_tsne_e=np.array(vis_tsne_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plotting\n",
    "scatter_polt_size=350\n",
    "plt.scatter(vis_tsne_a[:, 0], vis_tsne_a[:, 1],marker=\"X\",s=scatter_polt_size,color='red',label='1')\n",
    "plt.scatter(vis_tsne_b[:, 0], vis_tsne_b[:, 1],marker=\"v\",s=scatter_polt_size,color='black',label='2')\n",
    "plt.scatter(vis_tsne_c[:, 0], vis_tsne_c[:, 1],marker='o',s=scatter_polt_size,color='blue',label='3')\n",
    "plt.scatter(vis_tsne_d[:, 0], vis_tsne_d[:, 1],marker=\"+\",s=scatter_polt_size,color='orange',label='4')\n",
    "plt.scatter(vis_tsne_e[:, 0], vis_tsne_e[:, 1],marker=\"x\",s=scatter_polt_size,color='green',label='5')\n",
    "plt.legend(bbox_to_anchor=(1.37, 1.025))\n",
    "plt.show()\n",
    "plt.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=num_class_test,random_state=1)\n",
    "y_km = kmeans.fit_predict(points)\n",
    "print(points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Accuracy for our method\n",
    "num_test_video_per_class=num_videos_per_class_test\n",
    "y_true_a=np.ones(num_test_video_per_class)*1\n",
    "y_true_b=np.ones(num_test_video_per_class)*2\n",
    "y_true_c=np.ones(num_test_video_per_class)*3\n",
    "y_true_d=np.ones(num_test_video_per_class)*4\n",
    "y_true_e=np.ones(num_test_video_per_class)*5\n",
    "y_true=np.concatenate((y_true_a,y_true_b,y_true_c,y_true_d,y_true_e),axis=0)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Adjusted random Index:',round(metrics.adjusted_rand_score(y_true,y_km),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Adjusted mutual infromation score:',metrics.adjusted_mutual_info_score(y_true,y_km))\n",
    "print('Homogeneity score:',metrics.homogeneity_score(y_true,y_km))\n",
    "print('V measure score:',round(metrics.v_measure_score(y_true,y_km),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
